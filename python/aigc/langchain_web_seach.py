import os
import time
from abc import ABC

from langchain_core.output_parsers import StrOutputParser
from langchain_core.language_models import BaseChatModel
from langchain_core.messages import AIMessage, AIMessageChunk, HumanMessage, SystemMessage, BaseMessage
from langchain_core.outputs import ChatResult, ChatGeneration, ChatGenerationChunk
from typing import Any, List, Optional, Dict, Iterator, Generator
import requests
import json
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate

"""
å›ç­”ç³»ç»Ÿæç¤ºè¯
"""
SYSTEM_CHAIN_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIç ”ç©¶åŠ©æ‰‹ï¼Œæ“…é•¿æ·±åº¦ç½‘ç»œæœç´¢å’Œä¿¡æ¯ç»¼åˆåˆ†æã€‚

# æ ¸å¿ƒèƒ½åŠ›
- ç†è§£å¤æ‚é—®é¢˜çš„æ·±å±‚éœ€æ±‚
- è§„åˆ’å¤šæ­¥éª¤æœç´¢ç­–ç•¥
- ç»¼åˆåˆ†æä¸åŒæ¥æºçš„ä¿¡æ¯
- æä¾›æœ‰æ·±åº¦ã€æœ‰ä¾æ®çš„ç­”æ¡ˆ

# è¾“å‡ºè¦æ±‚
- ä½¿ç”¨ä¸­æ–‡å›ç­”
- ç»“æ„æ¸…æ™°ï¼Œåˆ†ç‚¹è®ºè¿°
- å¦‚ä¿¡æ¯ä¸è¶³æˆ–å­˜åœ¨çŸ›ç›¾ï¼Œéœ€æ˜ç¡®æŒ‡å‡º
- é¿å…ä¸»è§‚è‡†æ–­ï¼ŒåŸºäºäº‹å®åˆ†æ
"""

"""
åˆ†æé—®é¢˜æç¤ºè¯
"""
QUESTION_ANALYZER_CHAIN_SYSTEM_CHAIN = """
# è§’è‰²ï¼šç ”ç©¶åˆ†æä¸“å®¶
æ‚¨æ˜¯ä¸€ä½èµ„æ·±ç ”ç©¶åˆ†æå¸ˆï¼Œæ“…é•¿æ·±åº¦è§£æ„ç”¨æˆ·é—®é¢˜ï¼Œè¯†åˆ«æ ¸å¿ƒç ”ç©¶éœ€æ±‚ï¼Œè§„åˆ’æ¸…æ™°çš„è°ƒç ”è·¯å¾„

## æ ¸å¿ƒèƒ½åŠ›
- æ‰¹åˆ¤æ€§æ€ç»´ä¸æ¦‚å¿µåˆ†æ
- é—®é¢˜æ‹†è§£ä¸æ¡†æ¶æ„å»º  
- ç ”ç©¶æ–¹æ³•è®¾è®¡

## è¾“å‡ºè§„èŒƒ
è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼š
    "core_question": "é—®é¢˜æœ¬è´¨çš„ç²¾ç‚¼è¡¨è¿°",
    "sub_questions": [
        "éœ€è¦ä¼˜å…ˆè§£ç­”çš„å­é—®é¢˜1",
        "éœ€è¦ä¼˜å…ˆè§£ç­”çš„å­é—®é¢˜2",
        "éœ€è¦ä¼˜å…ˆè§£ç­”çš„å­é—®é¢˜3"
    ],
    "key_concepts": [
        "éœ€è¦æ˜ç¡®å®šä¹‰çš„æ ¸å¿ƒæ¦‚å¿µ1",
        "éœ€è¦æ˜ç¡®å®šä¹‰çš„æ ¸å¿ƒæ¦‚å¿µ2"
    ],
    "search_focus": [
        "é‡ç‚¹è°ƒç ”æ–¹å‘1",
        "é‡ç‚¹è°ƒç ”æ–¹å‘2"
    ]
"""

QUESTION_ANALYZER_CHAIN_HUMAN_CHAIN = """
è¯·åˆ†æä»¥ä¸‹é—®é¢˜ï¼š

{question}
"""

"""
æœç´¢ç­–ç•¥ç”Ÿæˆæç¤ºè¯
"""
STRATEGY_HUMAN_CHAIN_PROMPT = """
## é—®é¢˜åˆ†æ
{analysis_result}

## ä»»åŠ¡
åŸºäºé—®é¢˜åˆ†æï¼Œè®¾è®¡ä¸‰è½®æœç´¢ç­–ç•¥ï¼š

## è¾“å‡ºè¦æ±‚
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

{{
    "search_rounds": [
        {{
            "round": 1,
            "purpose": "ç¬¬ä¸€è½®æœç´¢çš„ç›®çš„",
            "search_text": "æœç´¢è¯æ¡",
            "expected_info": "æœŸæœ›è·å–çš„ä¿¡æ¯ç±»å‹"
        }},
        {{
            "round": 2, 
            "purpose": "ç¬¬äºŒè½®æœç´¢çš„ç›®çš„",
            "search_text": "æœç´¢è¯æ¡",
            "expected_info": "æœŸæœ›è·å–çš„ä¿¡æ¯ç±»å‹"
        }},
        {{
            "round": 3,
            "purpose": "ç¬¬ä¸‰è½®æœç´¢çš„ç›®çš„", 
            "search_text": "æœç´¢è¯æ¡",
            "expected_info": "æœŸæœ›è·å–çš„ä¿¡æ¯ç±»å‹"
        }}
    ]
}}
"""

"""
æ•´ç†å’Œæ¸…æ´—æœç´¢æ•°æ®æç¤ºè¯
"""
ORGANIZER_CHAIN_HUMAN_PROMPT = """
## è§’è‰²
ä½ æ˜¯ä¿¡æ¯æ•´ç†ä¸“å®¶ï¼Œè´Ÿè´£ä»æœç´¢ç»“æœä¸­æå–å’Œæ•´ç†æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚

## ç”¨æˆ·é—®é¢˜
{question}

## æœç´¢åˆ°çš„åŸå§‹ä¿¡æ¯
{search_results}

## ä½ çš„ä»»åŠ¡
ä»”ç»†é˜…è¯»æ‰€æœ‰æœç´¢ç»“æœï¼Œæå–å…³é”®ä¿¡æ¯å¹¶åˆ†ç±»æ•´ç†ã€‚é‡ç‚¹ä¿ç•™å…·ä½“ç»†èŠ‚å’Œæ•°æ®ï¼Œä¸è¦è¿‡åº¦æ¦‚æ‹¬ã€‚

## æ ¹æ®é—®é¢˜ç±»å‹çµæ´»è°ƒæ•´
- **æŠ€æœ¯é—®é¢˜**ï¼šä¾§é‡å…·ä½“é…ç½®ã€æ­¥éª¤ã€å‚æ•°
- **å•†ä¸šåˆ†æ**ï¼šä¾§é‡æ•°æ®ã€è¶‹åŠ¿ã€ç«äº‰ä¿¡æ¯  
- **ç”Ÿæ´»å»ºè®®**ï¼šä¾§é‡å®ç”¨æ–¹æ³•ã€æ³¨æ„äº‹é¡¹
- **å­¦æœ¯ç ”ç©¶**ï¼šä¾§é‡ç†è®ºã€è¯æ®ã€ä¸åŒè§‚ç‚¹
- **äº§å“æ¯”è¾ƒ**ï¼šä¾§é‡å…·ä½“å·®å¼‚ã€ä¼˜ç¼ºç‚¹

## æ•´ç†åŸåˆ™
1. **ä¿ç•™ç»†èŠ‚**ï¼šä¿æŒå…·ä½“çš„æ•°å­—ã€åç§°ã€æ—¶é—´ã€åœ°ç‚¹ç­‰å…³é”®ä¿¡æ¯
2. **åˆ†ç±»åˆç†**ï¼šæ ¹æ®é—®é¢˜ç±»å‹è‡ªåŠ¨è°ƒæ•´åˆ†ç±»é€»è¾‘
3. **æ ‡æ³¨æ¥æº**ï¼šæ¯ä¸ªä¿¡æ¯éƒ½è¦æ³¨æ˜å‡ºå¤„å’Œå¯ä¿¡åº¦
4. **é¿å…è¿‡åº¦æç‚¼**ï¼šä¸è¦ä¸ºäº†ç®€æ´è€Œä¸¢å¤±é‡è¦ç»†èŠ‚

## é€šç”¨åˆ†ç±»æ¡†æ¶
è¯·æ ¹æ®é—®é¢˜æ€§è´¨ï¼Œä½¿ç”¨ä¸€ä¸‹ç»“æ„è¿›è¡Œè¾“å‡ºï¼š
{{
    "organized_info": {{
        "core_facts": [
            {{
                "fact": "å…·ä½“çš„äº‹å®æè¿°ï¼Œä¿ç•™åŸå§‹ç»†èŠ‚",
                "context": "äº‹å®çš„èƒŒæ™¯æˆ–ä¸Šä¸‹æ–‡",
                "source": "æ¥æºä¿¡æ¯",
                "url": "æ¥æºé“¾æ¥",
                "reliability": "é«˜/ä¸­/ä½",
                "timestamp": "ä¿¡æ¯æ—¶é—´ï¼ˆå¦‚æœ‰ï¼‰"
            }}
        ],
        "key_data_points": [
            {{
                "data_description": "æ•°æ®çš„å…·ä½“å«ä¹‰",
                "value": "å…·ä½“çš„æ•°å€¼æˆ–å†…å®¹",
                "unit": "å•ä½ï¼ˆå¦‚æœ‰ï¼‰",
                "timeframe": "æ•°æ®å¯¹åº”çš„æ—¶é—´èŒƒå›´",
                "source": "æ¥æºä¿¡æ¯",
                "url": "æ¥æºé“¾æ¥",
                "significance": "è¿™ä¸ªæ•°æ®çš„é‡è¦æ€§"
            }}
        ],
        "practical_details": [
            {{
                "category": "ä¿¡æ¯ç±»åˆ«ï¼ˆå¦‚æ­¥éª¤ã€æ–¹æ³•ã€é…ç½®ç­‰ï¼‰",
                "specific_content": "å…·ä½“çš„å†…å®¹æè¿°ï¼Œä¿ç•™æ“ä½œç»†èŠ‚",
                "applicability": "é€‚ç”¨æ¡ä»¶æˆ–åœºæ™¯",
                "source": "æ¥æºä¿¡æ¯",
                "url": "æ¥æºé“¾æ¥"
            }}
        ],
        "expert_insights": [
            {{
                "viewpoint": "å…·ä½“çš„è§‚ç‚¹æˆ–åˆ†æ",
                "supporting_evidence": "æ”¯æ’‘è¯¥è§‚ç‚¹çš„è¯æ®",
                "expert_background": "ä¸“å®¶èƒŒæ™¯ï¼ˆå¦‚æœ‰ï¼‰",
                "source": "æ¥æºä¿¡æ¯",
                "url": "æ¥æºé“¾æ¥",
                "credibility": "å¯ä¿¡åº¦è¯„ä¼°"
            }}
        ],
        "comparative_info": [
            {{
                "comparison_aspect": "æ¯”è¾ƒçš„ç»´åº¦",
                "option_a": "é€‰é¡¹Açš„å…·ä½“ä¿¡æ¯",
                "option_b": "é€‰é¡¹Bçš„å…·ä½“ä¿¡æ¯",
                "differences": "å…·ä½“çš„å·®å¼‚ç‚¹",
                "source": "æ¥æºä¿¡æ¯",
                "url": "æ¥æºé“¾æ¥"
            }}
        ],
        "actionable_advice": [
            {{
                "advice_type": "å»ºè®®ç±»å‹",
                "concrete_steps": "å…·ä½“çš„æ­¥éª¤æˆ–æ–¹æ³•",
                "expected_outcome": "é¢„æœŸç»“æœ",
                "precautions": "æ³¨æ„äº‹é¡¹",
                "source": "æ¥æºä¿¡æ¯",
                "url": "æ¥æºé“¾æ¥"
            }}
        ]
    }}
}}
"""

"""
æ·±åº¦æ€è€ƒæç¤ºè¯
"""
DEEP_ANALYZER_CHAIN_PROMPT = """
## è§’è‰²
ä½ æ˜¯æ€è€ƒæ·±å…¥çš„è¡Œä¸šè§‚å¯Ÿè€…ï¼Œå–„äºä»å…·ä½“ä¿¡æ¯ä¸­å‘ç°æœ‰ä»·å€¼çš„æ¨¡å¼å’Œæ´å¯Ÿã€‚

## åˆ†æåŸºç¡€
ç ”ç©¶é—®é¢˜: {question}

æ•´ç†åçš„å…·ä½“ä¿¡æ¯:
{organized_data}

## ä½ çš„ä»»åŠ¡
åŸºäºè¿™äº›å…·ä½“ä¿¡æ¯ï¼Œè¿›è¡Œæ·±åº¦æ€è€ƒå’Œåˆ†æã€‚é‡ç‚¹ä¸æ˜¯é‡å¤äº‹å®ï¼Œè€Œæ˜¯å‘ç°ï¼š
- ä¿¡æ¯ä¹‹é—´çš„å…³è”å’Œæ¨¡å¼
- ç°è±¡èƒŒåçš„åŸå› å’Œé€»è¾‘  
- å¯èƒ½çš„å‘å±•è¶‹åŠ¿å’Œå½±å“
- å¯¹ç”¨æˆ·æœ‰å®é™…ä»·å€¼çš„æ´å¯Ÿ

## åˆ†æç»´åº¦ï¼ˆæ ¹æ®ä¿¡æ¯ç±»å‹é€‰æ‹©é‡ç‚¹ï¼‰

### å¦‚æœä¿¡æ¯åå‘äº‹å®æ•°æ®ï¼š
- è¿™äº›æ•°æ®è¯´æ˜äº†ä»€ä¹ˆè¶‹åŠ¿æˆ–æ¨¡å¼ï¼Ÿ
- ä¸åŒæ•°æ®ç‚¹ä¹‹é—´æœ‰ä»€ä¹ˆå…³è”ï¼Ÿ
- è¿™äº›æ•°æ®çš„å®é™…æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ

### å¦‚æœä¿¡æ¯åå‘æ–¹æ³•æ­¥éª¤ï¼š
- è¿™äº›æ–¹æ³•èƒŒåçš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ
- ä¸åŒæ–¹æ³•çš„ä¼˜ç¼ºç‚¹å’Œé€‚ç”¨åœºæ™¯ï¼Ÿ
- æ‰§è¡Œæ—¶å¯èƒ½é‡åˆ°ä»€ä¹ˆæŒ‘æˆ˜ï¼Ÿ

### å¦‚æœä¿¡æ¯åå‘è§‚ç‚¹åˆ†æï¼š
- ä¸åŒè§‚ç‚¹ä¹‹é—´çš„å…±è¯†å’Œåˆ†æ­§åœ¨å“ªé‡Œï¼Ÿ
- è¿™äº›è§‚ç‚¹èƒŒåçš„å‡è®¾å’Œä¾æ®ï¼Ÿ
- å“ªäº›è§‚ç‚¹æ›´æœ‰è¯´æœåŠ›ï¼Œä¸ºä»€ä¹ˆï¼Ÿ

### å¦‚æœä¿¡æ¯åå‘æ¯”è¾ƒé€‰æ‹©ï¼š
- å„é€‰é¡¹çš„æ ¸å¿ƒå·®å¼‚å’Œæƒè¡¡ç‚¹ï¼Ÿ
- é€‰æ‹©æ—¶æœ€åº”è¯¥è€ƒè™‘çš„å› ç´ ï¼Ÿ
- é•¿æœŸæ¥çœ‹å“ªä¸ªé€‰æ‹©æ›´æœ‰ä¼˜åŠ¿ï¼Ÿ

## è¾“å‡ºè¦æ±‚
è¯·ç”Ÿæˆæœ‰æ·±åº¦çš„åˆ†æï¼ŒåŒ…å«ï¼š

{{
    "analysis_insights": {{
        "pattern_observations": [
            "åŸºäºå…·ä½“ä¿¡æ¯è§‚å¯Ÿåˆ°çš„æ¨¡å¼æˆ–è¶‹åŠ¿",
            "ä¿¡æ¯ä¹‹é—´æœ‰è¶£çš„å…³è”æ€§"
        ],
        "underlying_factors": [
            "ç°è±¡èƒŒåçš„å¯èƒ½åŸå› ",
            "é©±åŠ¨è¿™äº›å‘å±•çš„å…³é”®å› ç´ "
        ],
        "practical_implications": [
            "è¿™äº›ä¿¡æ¯å¯¹ç”¨æˆ·çš„å®é™…æ„ä¹‰",
            "å¯èƒ½äº§ç”Ÿçš„å½±å“æˆ–åæœ"
        ],
        "forward_looking_views": [
            "åŸºäºç°çŠ¶çš„åˆç†æ¨æµ‹",
            "å€¼å¾—å…³æ³¨çš„å‘å±•æ–¹å‘"
        ],
        "critical_considerations": [
            "éœ€è¦è­¦æƒ•çš„æ–¹é¢æˆ–æ½œåœ¨é£é™©",
            "ä¿¡æ¯çš„å±€é™æ€§æˆ–ä¸ç¡®å®šæ€§"
        ]
    }}
}}

## ç‰¹åˆ«æé†’
- æ¯ä¸ªæ´å¯Ÿéƒ½è¦åŸºäºå‰é¢æ•´ç†çš„å…·ä½“ä¿¡æ¯
- é¿å…ç©ºæ³›çš„ç»“è®ºï¼Œè¦æœ‰å…·ä½“çš„æ”¯æ’‘ç‚¹
- å¯ä»¥æœ‰è‡ªå·±çš„æ¨ç†ï¼Œä½†è¦æ ‡æ˜æ˜¯åˆ†ææ¨æ–­
- ç”¨å¹³å®çš„è¯­è¨€è¡¨è¾¾æ·±åº¦æ€è€ƒ
"""

"""
æ€»ç»“å›ç­”æç¤ºè¯
"""
REPORT_GENERATOR_CHAIN_HUMAN_PROMPT = """
ç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼š
{question}

ç½‘ç»œè°ƒç ”å‘ç°çš„ç»“æœï¼š
{analysis_result}

æ·±åº¦æ´å¯Ÿåçš„ç»“æœï¼š
{deep_analysis}

è¯·å›´ç»•ç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼Œç»“åˆç½‘ç»œè°ƒç ”å‘ç°çš„ç»“æœä»¥åŠæ·±åº¦æ´å¯Ÿåçš„ç»“æœæ¥å›ç­”ç”¨æˆ·

# æ–‡æœ«æ ¼å¼åŒ–æ ‡æ³¨æ¥æºä¿¡æ¯å’Œç½‘é¡µé“¾æ¥ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
**å‚è€ƒèµ„æ–™**
[ç½‘é¡µ1æ ‡é¢˜](ç½‘é¡µ1é“¾æ¥åœ°å€)
[ç½‘é¡µ2æ ‡é¢˜](ç½‘é¡µ2é“¾æ¥åœ°å€)
[ç½‘é¡µ3æ ‡é¢˜](ç½‘é¡µ3é“¾æ¥åœ°å€)
......
å‚è€ƒèµ„æ–™ä¸è¦èƒ¡ç¼–ä¹±é€ ï¼Œè¦å¡«å†™{{analysis_result}}ä¸­çš„çœŸå®ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰å°±ä¸è¦å¡«
"""


class BaiduApi:
    """ç™¾åº¦æœç´¢APIå°è£…ç±»"""

    """api_key å¯åœ¨å®˜ç½‘ç”³è¯·"""
    api_key: str = ''

    def web_search(self, query):
        """æ‰§è¡Œç™¾åº¦ç½‘é¡µæœç´¢"""
        url = "https://qianfan.baidubce.com/v2/ai_search/web_search"

        payload = json.dumps({
            "messages": [
                {
                    "role": "user",
                    "content": query
                }
            ],
            "edition": "standard",
            "search_source": "baidu_search_v2",
            "search_recency_filter": "week"
        }, ensure_ascii=False)
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.api_key}'
        }
        # å‘é€POSTè¯·æ±‚åˆ°ç™¾åº¦æœç´¢API
        response = requests.request("POST", url, headers=headers, data=payload.encode("utf-8"))
        return response.json()


def md2json(content):
    """å°†markdownæ ¼å¼çš„JSONå­—ç¬¦ä¸²è½¬æ¢ä¸ºPythonå­—å…¸"""
    content = content.lstrip("```json")  # å»é™¤å¼€å¤´çš„```jsonæ ‡è®°
    content = content.rstrip("```")  # å»é™¤ç»“å°¾çš„```æ ‡è®°
    return json.loads(content)  # è§£æJSONå­—ç¬¦ä¸²


class DeepSeekChatModel(BaseChatModel, ABC):
    """å…¼å®¹ LangChain Expression Language (LCEL) çš„ DeepSeek Chat æ¨¡å‹"""

    api_key: str
    model_name: str = "deepseek-chat"  # æ¨¡å‹åç§°
    api_url: str = "https://api.deepseek.com/v1/chat/completions"  # APIåœ°å€
    temperature: float = 0.7  # ç”Ÿæˆæ¸©åº¦å‚æ•°
    timeout: int = 3000  # è¯·æ±‚è¶…æ—¶æ—¶é—´

    def _convert_messages(self, messages: List[BaseMessage]) -> List[dict]:
        """å°† LangChain çš„ Message å¯¹è±¡è½¬æ¢ä¸º DeepSeek æ‰€éœ€æ ¼å¼"""
        result = []
        for msg in messages:
            if isinstance(msg, HumanMessage):
                role = "user"  # ç”¨æˆ·æ¶ˆæ¯
            elif isinstance(msg, AIMessage):
                role = "assistant"  # AIåŠ©æ‰‹æ¶ˆæ¯
            elif isinstance(msg, SystemMessage):
                role = "system"  # ç³»ç»Ÿæ¶ˆæ¯
            else:
                role = "user"  # é»˜è®¤ç”¨æˆ·æ¶ˆæ¯
            result.append({"role": role, "content": msg.content})
        return result

    # --- æµå¼è°ƒç”¨ ---
    def _stream(
            self, messages: List[BaseMessage], stop: Optional[List[str]] = None, **kwargs: Any
    ) -> Generator[ChatGenerationChunk, None, None]:
        """æµå¼è¿”å› ChatGenerationChunk"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": self.model_name,
            "messages": self._convert_messages(messages),
            "temperature": self.temperature,
            "stream": True  # å¼€å¯æµå¼è¾“å‡º
        }

        # å‘é€æµå¼è¯·æ±‚
        with requests.post(
                self.api_url, headers=headers, json=payload, stream=True, timeout=self.timeout
        ) as response:
            if response.status_code != 200:
                raise ValueError(f"DeepSeek æµå¼æ¥å£é”™è¯¯: {response.status_code} - {response.text}")

            # å¤„ç†æµå¼å“åº”
            for line in response.iter_lines():
                if not line:
                    continue
                if line.startswith(b"data: "):
                    data = line[len(b"data: "):].decode("utf-8")
                    if data.strip() == "[DONE]":  # æµå¼ç»“æŸæ ‡è®°
                        break
                    try:
                        chunk = json.loads(data)
                        delta = chunk["choices"][0]["delta"]
                        if "content" in delta:
                            text = delta["content"]
                            yield ChatGenerationChunk(
                                message=AIMessageChunk(content=text)
                            )
                    except Exception:
                        continue

    def _generate(self, messages: List[BaseMessage], stop: Optional[List[str]] = None, **kwargs: Any) -> ChatResult:
        """æ ¸å¿ƒè°ƒç”¨é€»è¾‘ - ç”ŸæˆèŠå¤©å“åº”"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": self.model_name,
            "messages": self._convert_messages(messages),
            "temperature": self.temperature,
        }

        # å‘é€APIè¯·æ±‚
        response = requests.post(self.api_url, headers=headers, json=payload, timeout=self.timeout)
        if response.status_code != 200:
            raise ValueError(f"DeepSeek API è°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")

        # è§£æå“åº”æ•°æ®
        data = response.json()
        content = data["choices"][0]["message"]["content"]

        # å¤„ç†åœæ­¢è¯
        if stop:
            for s in stop:
                content = content.split(s)[0]

        # è¿”å›ç¬¦åˆ LangChain æ ¸å¿ƒç»“æ„çš„ ChatResult
        gen = ChatGeneration(message=AIMessage(content=content))
        return ChatResult(generations=[gen])

    @property
    def _llm_type(self) -> str:
        """è¿”å›LLMç±»å‹æ ‡è¯†"""
        return "deepseek-chat-lcel"

    @property
    def _identifying_params(self) -> dict:
        """è¿”å›æ¨¡å‹è¯†åˆ«å‚æ•°"""
        return {
            "model_name": self.model_name,
            "api_url": self.api_url,
            "temperature": self.temperature,
        }


class DeepWebSearchChinese:
    """ä¸­æ–‡æ·±åº¦ç½‘ç»œæœç´¢å™¨ - ä¸»ç±»"""

    def __init__(self):
        # åˆå§‹åŒ–DeepSeekæ¨¡å‹å’Œç™¾åº¦æœç´¢API
        self.llmModel = DeepSeekChatModel(api_key="") ## api_keyå¯åœ¨å®˜ç½‘ç”³è¯·
        self.search = BaiduApi()

    def web_search(self, query):
        """æ‰§è¡Œç½‘ç»œæœç´¢å¹¶ä¼˜åŒ–ç»“æœ"""
        print(f"ğŸ” æ‰§è¡Œæœç´¢: {query}")
        try:
            answer = self.search.web_search(query)
            return answer
        except Exception as e:
            return f"æœç´¢æ‰§è¡Œé”™è¯¯: {str(e)}"

    def question_analyzer_chain(self, question):
        """é—®é¢˜åˆ†æé“¾ - è§£æç”¨æˆ·é—®é¢˜"""
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", QUESTION_ANALYZER_CHAIN_SYSTEM_CHAIN),
                ("human", QUESTION_ANALYZER_CHAIN_HUMAN_CHAIN),
            ]
        )
        ## LCELå†™æ³•åˆ›å»ºchain
        chain = (
                prompt
                | self.llmModel
                | StrOutputParser()
        )
        return chain.invoke({"question": question})

    def strategy_human_chain(self, analyzer):
        """æœç´¢ç­–ç•¥ç”Ÿæˆé“¾ - åˆ¶å®šæœç´¢è®¡åˆ’"""
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", SYSTEM_CHAIN_PROMPT),
                ("human", STRATEGY_HUMAN_CHAIN_PROMPT),
            ]
        )
        ## LCELå†™æ³•åˆ›å»ºchain
        chain = (
                prompt
                | self.llmModel
                | StrOutputParser()
        )
        return chain.invoke({"analysis_result": analyzer})

    def organizer_chain(self, question, search_results):
        """æ•°æ®æ•´ç†é“¾ - æ¸…æ´—å’Œç»„ç»‡æœç´¢ç»“æœ"""
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", ORGANIZER_CHAIN_HUMAN_PROMPT),
                ("human", "è¯·å¼€å§‹æ•´ç†æ•°æ®"),
            ]
        )
        ## LCELå†™æ³•åˆ›å»ºchain
        chain = (
                prompt
                | self.llmModel
                | StrOutputParser()
        )
        return chain.invoke({"question": question, "search_results": search_results})

    def deep_analyzer_chain(self, question, organized_data):
        """æ·±åº¦åˆ†æé“¾ - å¯¹æ•´ç†åçš„æ•°æ®è¿›è¡Œæ·±å…¥åˆ†æ"""
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", DEEP_ANALYZER_CHAIN_PROMPT),
                ("human", "è¯·å¼€å§‹æ·±åº¦åˆ†æ"),
            ]
        )
        ## LCELå†™æ³•åˆ›å»ºchain
        chain = (
                prompt
                | self.llmModel
                | StrOutputParser()
        )
        return chain.invoke({"question": question, "organized_data": organized_data})

    def report_generator_chain(self, question, analysis_result, deep_analysis):
        """æŠ¥å‘Šç”Ÿæˆé“¾ - ç”Ÿæˆæœ€ç»ˆå›ç­”æŠ¥å‘Š"""
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", SYSTEM_CHAIN_PROMPT),
                ("human", REPORT_GENERATOR_CHAIN_HUMAN_PROMPT),
            ]
        )
        ## LCELå†™æ³•åˆ›å»ºchain
        chain = (
                prompt
                | self.llmModel
                | StrOutputParser()
        )
        return chain.invoke({"question": question, "analysis_result": analysis_result, "deep_analysis": deep_analysis})

    def search_chain(self, strategy_result):
        """æ‰§è¡Œæœç´¢é“¾ - æ ¹æ®ç­–ç•¥æ‰§è¡Œå¤šè½®æœç´¢"""
        search_content = []
        # éå†æ¯ä¸€è½®æœç´¢ç­–ç•¥
        for search_rounds in strategy_result['search_rounds']:
            print(f"çœŸæ­£è¿›è¡Œç¬¬{search_rounds['round']}è½®æœç´¢")
            # æ‰§è¡Œæœç´¢
            res = self.search.web_search(search_rounds['search_text'])
            # å¤„ç†æœç´¢ç»“æœ
            for references in res['references']:
                print(references)
                search_content.append({
                    'url': references['url'],  # ç½‘é¡µURL
                    'title': references['title'],  # ç½‘é¡µæ ‡é¢˜
                    'content': references['content']  # ç½‘é¡µå†…å®¹
                })
        return search_content

    def main_chain(self, question):
        """ä¸»æ‰§è¡Œé“¾ - åè°ƒæ•´ä¸ªæœç´¢åˆ†ææµç¨‹"""
        print(f"{'=' * 80}\nåˆ†æé—®é¢˜\n{'=' * 80}\n")
        analyzer_result = self.question_analyzer_chain(question)
        print(analyzer_result)

        print(f"{'=' * 80}\næœç´¢ç­–ç•¥ç”Ÿæˆ\n{'=' * 80}\n")
        strategy_result = self.strategy_human_chain(md2json(analyzer_result))
        print(strategy_result)

        print(f"{'=' * 80}\nå¼€å§‹æœç´¢\n{'=' * 80}\n")
        search_result = self.search_chain(md2json(strategy_result))
        print(search_result)

        print(f"{'=' * 80}\nå¼€å§‹æ•´ç†å’Œæ¸…æ´—æœç´¢æ•°æ®\n{'=' * 80}\n")
        organizer_result = self.organizer_chain(question, search_result)
        print(organizer_result)

        print(f"{'=' * 80}\nå¼€å§‹æ·±åº¦åˆ†æ\n{'=' * 80}\n")
        deep_analyzer_result = self.deep_analyzer_chain(question, organizer_result)
        print(deep_analyzer_result)

        print(f"{'=' * 80}\næ„å»ºç»“æœ\n{'=' * 80}\n")
        final_report = self.report_generator_chain(question, organizer_result, deep_analyzer_result)
        print(final_report)
        return final_report


if __name__ == '__main__':
    # åˆå§‹åŒ–æ·±åº¦æœç´¢å™¨
    searcher = DeepWebSearchChinese()

    question = "ç»™æˆ‘ä¸€ä»½å½“å‰å»åŒ—æ–¹æ—…æ¸¸çš„è®¡åˆ’"
    searcher.main_chain(question)
